{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled68.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZ/zTrVIxLRM0qKsyKuhyF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/AdvancedPytorch_Colab/blob/master/RandomForest_and_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvNN7HMtmRIT"
      },
      "source": [
        "#**目次**\n",
        "1. Random Forest classifier\n",
        "2. Random Forest regressor\n",
        "3. XGBoost\n",
        "4. XGBoost (grid search)\n",
        "5. Voting regressor\n",
        "6. Support vector machine\n",
        "7. Neural network\n",
        "8. Multiple regression　<br>\n",
        "https://hinomaruc.hatenablog.com/entry/2019/12/07/000022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQZZYCaRRX3F"
      },
      "source": [
        "#**RandomForestClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "wcfiCY58HvWt",
        "outputId": "def457d7-94ba-40a6-ac23-d78f1ad4c4cc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def get_iris(target_name=False):\n",
        "    iris = load_iris()\n",
        "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "    df['Species'] = iris.target\n",
        "    if target_name:\n",
        "        df.Species = df.Species.apply(lambda x:'setosa' if x == 1 else 'versicolor' if x == 2 else 'virginica')\n",
        "\n",
        "    return df\n",
        "\n",
        "def plot_pairplot(df):\n",
        "    g = sns.pairplot(df, hue='Species', plot_kws={'alpha': 0.5}, palette='rainbow_r')\n",
        "\n",
        "    plt.show() \n",
        "\n",
        "def get_train_test_split(df):\n",
        "    X = df.drop('Species', axis=1)\n",
        "    y = df.Species\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def get_accuracy(X_train, X_test, y_train, y_test):\n",
        "    clf = RandomForestClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "    pred = clf.predict(X_test)\n",
        "    \n",
        "    print('予測値：', pred)\n",
        "    print('実測値：', np.array(y_test))\n",
        "    print('精度：', accuracy_score(pred, y_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nif __name__ == \"__main__\":\\n    # ペアプロットを出力\\n    df = get_iris(target_name=True)\\n    plot_pairplot(df)\\n\\n    # ランダムフォレストの実装\\n    df = get_iris()\\n    X_train, X_test, y_train, y_test = get_train_test_split(df)\\n    get_accuracy(X_train, X_test, y_train, y_test)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73aU9R-pHxuC"
      },
      "source": [
        "# ペアプロットを出力\n",
        "df = get_iris(target_name=True)\n",
        "print(df)\n",
        "plot_pairplot(df)\n",
        "\n",
        "# ランダムフォレストの実装\n",
        "df = get_iris()\n",
        "X_train, X_test, y_train, y_test = get_train_test_split(df)\n",
        "get_accuracy(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JSe1JrxRdyO"
      },
      "source": [
        "#**RandomForestRegressor**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/11/13/235327"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDJJGZcyRh6Y",
        "outputId": "f7abf70e-e084-45dc-cf24-e5563967af65"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "#import data\n",
        "df = pd.read_csv(\"http://lib.stat.cmu.edu/datasets/boston_corrected.txt\",skiprows=9,sep=\"\\t\")\n",
        "print(list(df.columns))\n",
        "\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "# 本当は町ごとにサンプリングした方がいいと思うが、TODOにしておく。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "# 変数の組み合わせは前回の重回帰分析と同じ\n",
        "X_train = train[[\"RM\",\"LSTAT\",\"PTRATIO\",\"B\"]]\n",
        "Y_train = train[\"CMEDV\"]\n",
        "X_test = test[[\"RM\",\"LSTAT\",\"PTRATIO\",\"B\"]]\n",
        "Y_test = test[\"CMEDV\"]\n",
        "\n",
        "\n",
        "#Create model\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['OBS.', 'TOWN', 'TOWN#', 'TRACT', 'LON', 'LAT', 'MEDV', 'CMEDV', 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9699130376171284',\n",
              " 'adjusted_r2(test)      :0.8111299380244453',\n",
              " '平均誤差率(test)       :0.14569204973193473',\n",
              " 'MAE(test)              :2.8734215686274487',\n",
              " 'MedianAE(test)         :2.1865000000000068',\n",
              " 'RMSE(test)             :4.183559481036758',\n",
              " 'RMSE(test) / MAE(test) :1.4559504691945095')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pihWZTW3tvx9"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 18,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol7HYSqg_7PV"
      },
      "source": [
        "#**XGBoost　regressor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNAX4t3TB6HY",
        "outputId": "b8556514-fba1-498d-a2ff-86c54bc67408"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"http://lib.stat.cmu.edu/datasets/boston_corrected.txt\",skiprows=9,sep=\"\\t\")\n",
        "print(list(df.columns))\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "model = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
        "model= model.fit(X_train, Y_train)\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,ereg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['OBS.', 'TOWN', 'TOWN#', 'TRACT', 'LON', 'LAT', 'MEDV', 'CMEDV', 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9060361673732533',\n",
              " 'adjusted_r2(test)      :0.8152194739166603',\n",
              " '平均誤差率(test)       :0.1392184041616745',\n",
              " 'MAE(test)              :2.8826258490829098',\n",
              " 'MedianAE(test)         :2.251912106515971',\n",
              " 'RMSE(test)             :4.1380190558357794',\n",
              " 'RMSE(test) / MAE(test) :1.4355033474608803')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lexhYTU8e42q"
      },
      "source": [
        "#**XGBoost regressor (grid search)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnks-BN9e4NJ",
        "outputId": "3bac9486-b3bf-45ad-b3a0-e642aa7e65b1"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"http://lib.stat.cmu.edu/datasets/boston_corrected.txt\",skiprows=9,sep=\"\\t\")\n",
        "print(df.columns)\n",
        "\n",
        "FEATURE_COLS=[\n",
        " #'OBS.',\n",
        " #'TOWN',\n",
        " #'TOWN#',\n",
        " #'TRACT',\n",
        " #'LON',\n",
        " #'LAT',\n",
        " #'MEDV',\n",
        " #'CMEDV',\n",
        " 'CRIM',\n",
        " 'ZN',\n",
        " 'INDUS',\n",
        " 'CHAS',\n",
        " 'NOX',\n",
        " 'RM',\n",
        " 'AGE',\n",
        " 'DIS',\n",
        " 'RAD',\n",
        " 'TAX',\n",
        " 'PTRATIO',\n",
        " 'B',\n",
        " 'LSTAT']\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"CMEDV\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"CMEDV\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['OBS.', 'TOWN', 'TOWN#', 'TRACT', 'LON', 'LAT', 'MEDV', 'CMEDV', 'CRIM',\n",
            "       'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
            "       'PTRATIO', 'B', 'LSTAT'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2zU_Pr3hb0M",
        "outputId": "a24c9b4a-c622-440f-941e-0326d8c63891"
      },
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "sorted(sklearn.metrics.SCORERS.keys())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['accuracy',\n",
              " 'adjusted_mutual_info_score',\n",
              " 'adjusted_rand_score',\n",
              " 'average_precision',\n",
              " 'balanced_accuracy',\n",
              " 'completeness_score',\n",
              " 'explained_variance',\n",
              " 'f1',\n",
              " 'f1_macro',\n",
              " 'f1_micro',\n",
              " 'f1_samples',\n",
              " 'f1_weighted',\n",
              " 'fowlkes_mallows_score',\n",
              " 'homogeneity_score',\n",
              " 'jaccard',\n",
              " 'jaccard_macro',\n",
              " 'jaccard_micro',\n",
              " 'jaccard_samples',\n",
              " 'jaccard_weighted',\n",
              " 'max_error',\n",
              " 'mutual_info_score',\n",
              " 'neg_brier_score',\n",
              " 'neg_log_loss',\n",
              " 'neg_mean_absolute_error',\n",
              " 'neg_mean_gamma_deviance',\n",
              " 'neg_mean_poisson_deviance',\n",
              " 'neg_mean_squared_error',\n",
              " 'neg_mean_squared_log_error',\n",
              " 'neg_median_absolute_error',\n",
              " 'neg_root_mean_squared_error',\n",
              " 'normalized_mutual_info_score',\n",
              " 'precision',\n",
              " 'precision_macro',\n",
              " 'precision_micro',\n",
              " 'precision_samples',\n",
              " 'precision_weighted',\n",
              " 'r2',\n",
              " 'recall',\n",
              " 'recall_macro',\n",
              " 'recall_micro',\n",
              " 'recall_samples',\n",
              " 'recall_weighted',\n",
              " 'roc_auc',\n",
              " 'roc_auc_ovo',\n",
              " 'roc_auc_ovo_weighted',\n",
              " 'roc_auc_ovr',\n",
              " 'roc_auc_ovr_weighted',\n",
              " 'v_measure_score']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWFMTWxmhilf",
        "outputId": "3c19a15d-a3eb-45e3-82c8-35c5559dbdfb"
      },
      "source": [
        "# Grid Search用のパラメータ作成。\n",
        "# あまり組み合わせが多いと時間がかかる(time consuming)\n",
        "params = {\n",
        "        'eta': [0.01],             # default = 0.3      \n",
        "        'gamma': [1,2,3],            # default = 0\n",
        "        'max_depth': [7,8,9],      # default = 6\n",
        "        'min_child_weight': [1],   # default = 1\n",
        "        'subsample': [0.8,1.0],        # default = 1\n",
        "        'colsample_bytree': [0.8,1.0], # default = 1\n",
        "        }\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 1)\n",
        "\n",
        "#最適解探索\n",
        "model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error', n_jobs=2, cv=kf.split(X_train,Y_train), verbose=3)\n",
        "\n",
        "\n",
        "grid.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  52 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:   12.2s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7f6c694fbe50>,\n",
              "             error_score=nan,\n",
              "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
              "                                    colsample_bylevel=1, colsample_bynode=1,\n",
              "                                    colsample_bytree=1, gamma=0,\n",
              "                                    importance_type='gain', learning_rate=0.1,\n",
              "                                    max_delta_step=0, max_depth=3,\n",
              "                                    min_child_weight=1, missing=None,\n",
              "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
              "                                    object...\n",
              "                                    random_state=0, reg_alpha=0, reg_lambda=1,\n",
              "                                    scale_pos_weight=1, seed=None, silent=None,\n",
              "                                    subsample=1, verbosity=1),\n",
              "             iid='deprecated', n_jobs=2,\n",
              "             param_grid={'colsample_bytree': [0.8, 1.0], 'eta': [0.01],\n",
              "                         'gamma': [1, 2, 3], 'max_depth': [7, 8, 9],\n",
              "                         'min_child_weight': [1], 'subsample': [0.8, 1.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbPcwitCim1H",
        "outputId": "9c16bfe1-2c08-47ac-eeb0-bc360d5b46ab"
      },
      "source": [
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ベストスコア:\n",
            "-9.521597384566473\n",
            "\n",
            "\n",
            "ベストestimator:\n",
            "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "             colsample_bynode=1, colsample_bytree=1.0, eta=0.01, gamma=1,\n",
            "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
            "             max_depth=8, min_child_weight=1, missing=None, n_estimators=100,\n",
            "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
            "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
            "             seed=None, silent=None, subsample=0.8, verbosity=1)\n",
            "\n",
            "\n",
            "ベストparams:\n",
            "{'colsample_bytree': 1.0, 'eta': 0.01, 'gamma': 1, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.8}\n",
            "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
            "0        0.113887      0.004881  ...        3.338332               13\n",
            "1        0.109256      0.003071  ...        3.008121               28\n",
            "2        0.122238      0.003608  ...        3.604727               14\n",
            "3        0.122113      0.004575  ...        3.091205                3\n",
            "4        0.138270      0.007538  ...        3.587853               10\n",
            "5        0.131126      0.003228  ...        3.336603               16\n",
            "6        0.105143      0.002988  ...        3.534128               12\n",
            "7        0.110157      0.005115  ...        3.063569               31\n",
            "8        0.121063      0.004655  ...        3.906213               18\n",
            "9        0.129891      0.012097  ...        3.216045               20\n",
            "10       0.134071      0.002706  ...        3.784700               23\n",
            "11       0.134691      0.004240  ...        3.211698               24\n",
            "12       0.106280      0.002849  ...        3.652105               15\n",
            "13       0.106591      0.004840  ...        2.931335               21\n",
            "14       0.119725      0.004484  ...        3.608104               27\n",
            "15       0.119480      0.006430  ...        3.159451               25\n",
            "16       0.132345      0.004546  ...        3.427829                6\n",
            "17       0.131547      0.003041  ...        3.258695               26\n",
            "18       0.124083      0.005040  ...        3.310947                2\n",
            "19       0.124746      0.006918  ...        2.482421               17\n",
            "20       0.139191      0.003661  ...        3.362307                1\n",
            "21       0.136558      0.002321  ...        2.833901                9\n",
            "22       0.152527      0.005879  ...        3.771992               19\n",
            "23       0.153948      0.007215  ...        2.849920               32\n",
            "24       0.125408      0.006428  ...        3.935594                5\n",
            "25       0.128423      0.007446  ...        2.994747               35\n",
            "26       0.136825      0.002857  ...        3.696758                4\n",
            "27       0.137793      0.003554  ...        3.078822               34\n",
            "28       0.153206      0.002200  ...        3.791225               11\n",
            "29       0.148062      0.002125  ...        3.153908               36\n",
            "30       0.121894      0.000906  ...        3.521852                7\n",
            "31       0.121751      0.005926  ...        3.360359               30\n",
            "32       0.137931      0.002185  ...        3.553881                8\n",
            "33       0.137041      0.004702  ...        3.174940               29\n",
            "34       0.151819      0.001404  ...        3.764085               22\n",
            "35       0.147984      0.007665  ...        3.229207               33\n",
            "\n",
            "[36 rows x 19 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr8c_Vrni82u",
        "outputId": "e01e6600-ea08-4274-fe48-ae4f9d401ef2"
      },
      "source": [
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9979849458983184',\n",
              " 'adjusted_r2(test)      :0.9007293205261151',\n",
              " '平均誤差率(test)       :0.10292127436810407',\n",
              " 'MAE(test)              :2.0740456263224285',\n",
              " 'MedianAE(test)         :1.506885433197021',\n",
              " 'RMSE(test)             :2.8888856581918403',\n",
              " 'RMSE(test) / MAE(test) :1.3928746897020952')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaXCX-2fixDw"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 18,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=bestmodel.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRkUeICxlc4g"
      },
      "source": [
        "xgb.plot_importance(bestmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWyQQehDlf_8"
      },
      "source": [
        "xgb.to_graphviz(bestmodel, num_trees=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Fd8JsNB6Vr"
      },
      "source": [
        "#**Voting regressor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwzFGIasyZ6G",
        "outputId": "82c34aff-6369-409d-a879-5cc408718d50"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"http://lib.stat.cmu.edu/datasets/boston_corrected.txt\",skiprows=9,sep=\"\\t\")\n",
        "print(list(df.columns))\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "# GradientBoosting, RandomForest, 重回帰で試して見る\n",
        "# sklearnのサンプルと同じ\n",
        "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
        "reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
        "reg3 = LinearRegression(normalize=True)\n",
        "ereg = VotingRegressor(estimators=[('xgb', reg1), ('rf', reg2), ('lr', reg3)])\n",
        "\n",
        "ereg= ereg.fit(X_train, Y_train)\n",
        "print(ereg.estimators)\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,ereg)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['OBS.', 'TOWN', 'TOWN#', 'TRACT', 'LON', 'LAT', 'MEDV', 'CMEDV', 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
            "[('xgb', GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
            "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
            "                          max_features=None, max_leaf_nodes=None,\n",
            "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                          min_samples_leaf=1, min_samples_split=2,\n",
            "                          min_weight_fraction_leaf=0.0, n_estimators=10,\n",
            "                          n_iter_no_change=None, presort='deprecated',\n",
            "                          random_state=1, subsample=1.0, tol=0.0001,\n",
            "                          validation_fraction=0.1, verbose=0, warm_start=False)), ('rf', RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
            "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_impurity_split=None, min_samples_leaf=1,\n",
            "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
            "                      random_state=1, verbose=0, warm_start=False)), ('lr', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True))]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.8548861592039549',\n",
              " 'adjusted_r2(test)      :0.7794138810868475',\n",
              " '平均誤差率(test)       :0.14603260686642647',\n",
              " 'MAE(test)              :3.109038705038925',\n",
              " 'MedianAE(test)         :2.2944415916860663',\n",
              " 'RMSE(test)             :4.521197475831905',\n",
              " 'RMSE(test) / MAE(test) :1.4542107399641717')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPKwoDzaQl7l"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 18,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g8z78pjuMFg",
        "outputId": "2598c2bb-3e6f-461b-8b3a-0334522ea05a"
      },
      "source": [
        "# 組み合わせを変えてvoting regressor\n",
        "# xgboost, random forest, 重回帰でやってみる\n",
        "\n",
        "reg1 = xgb.XGBRegressor( objective ='reg:squarederror'\n",
        "                        , base_score=0.5\n",
        "                        , booster='gbtree'\n",
        "                        , colsample_bylevel=1\n",
        "                        , colsample_bynode=1\n",
        "                        , colsample_bytree=1\n",
        "                        , gamma=0\n",
        "                        , importance_type='gain'\n",
        "                        , learning_rate=0.1\n",
        "                        , max_delta_step=0\n",
        "                        , max_depth=3\n",
        "                        , min_child_weight=1\n",
        "                        , missing=None\n",
        "                        , n_estimators=100\n",
        "                        , n_jobs=1\n",
        "                        , nthread=None\n",
        "                        , random_state=0\n",
        "                        , reg_alpha=0\n",
        "                        , reg_lambda=1\n",
        "                        , scale_pos_weight=1\n",
        "                        , seed=None\n",
        "                        , silent=None\n",
        "                        , subsample=1\n",
        "                        , verbosity=1)\n",
        "reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
        "reg3 = LinearRegression(normalize=True)\n",
        "ereg = VotingRegressor(estimators=[('xgb', reg1), ('rf', reg2), ('lr', reg3)])\n",
        "\n",
        "ereg = ereg.fit(X_train, Y_train)\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,ereg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9060361673732533',\n",
              " 'adjusted_r2(test)      :0.8152194739166603',\n",
              " '平均誤差率(test)       :0.1392184041616745',\n",
              " 'MAE(test)              :2.8826258490829098',\n",
              " 'MedianAE(test)         :2.251912106515971',\n",
              " 'RMSE(test)             :4.1380190558357794',\n",
              " 'RMSE(test) / MAE(test) :1.4355033474608803')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvRhcshQCtxp"
      },
      "source": [
        "#**予測数値の平均をとるモデル**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOXJONNtC2h7"
      },
      "source": [
        "# XgBoost用\n",
        "X_train = train[FEATURE_COLS]\n",
        "X_test = test[FEATURE_COLS]\n",
        "\n",
        "# 変数を絞る (重回帰と多項式回帰用)\n",
        "X_train2 = train[[\"RM\",\"LSTAT\",\"PTRATIO\",\"B\"]] #部屋数、身分が低い人口割合、生徒と先生比率、人種スコアでの重回帰\n",
        "X_test2 = test[[\"RM\",\"LSTAT\",\"PTRATIO\",\"B\"]]\n",
        "\n",
        "# 目的変数(ターゲット)\n",
        "Y_train = train[\"CMEDV\"] #修正済み住宅価格中央値\n",
        "Y_test = test[\"CMEDV\"]\n",
        "\n",
        "\n",
        "\n",
        "# 多項式回帰用にデータセットを変換\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_features = PolynomialFeatures(degree = 2) # n=2\n",
        "\n",
        "X_train_poly = poly_features.fit_transform(X_train2)\n",
        "X_test_poly = poly_features.fit_transform(X_test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wplKn6m1DAAU",
        "outputId": "4762c93a-1b05-4117-c926-9caa2fc35b15"
      },
      "source": [
        "# 重回帰\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "multiple_regression = LinearRegression()\n",
        "multiple_regression.fit(X_train2,Y_train)\n",
        "\n",
        "\n",
        "# 多項式回帰\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "polynomial_regression = LinearRegression()\n",
        "polynomial_regression.fit(X_train_poly,Y_train)\n",
        "\n",
        "\n",
        "# XgBoost\n",
        "import xgboost as xgb\n",
        "xgboost = xgb.XGBRegressor( objective ='reg:squarederror'\n",
        "                        , base_score=0.5\n",
        "                        , booster='gbtree'\n",
        "                        , colsample_bylevel=1\n",
        "                        , colsample_bynode=1\n",
        "                        , colsample_bytree=1\n",
        "                        , gamma=0\n",
        "                        , importance_type='gain'\n",
        "                        , learning_rate=0.1\n",
        "                        , max_delta_step=0\n",
        "                        , max_depth=3\n",
        "                        , min_child_weight=1\n",
        "                        , missing=None\n",
        "                        , n_estimators=100\n",
        "                        , n_jobs=1\n",
        "                        , nthread=None\n",
        "                        , random_state=0\n",
        "                        , reg_alpha=0\n",
        "                        , reg_lambda=1\n",
        "                        , scale_pos_weight=1\n",
        "                        , seed=None\n",
        "                        , silent=None\n",
        "                        , subsample=1\n",
        "                        , verbosity=1)\n",
        "xgboost.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "\n",
        "#各モデルの予測値の平均を取る (テストデータ)\n",
        "yhat_test_1 = multiple_regression.predict(X_test2)\n",
        "yhat_test_2 = polynomial_regression.predict(X_test_poly)\n",
        "yhat_test_3 = xgboost.predict(X_test)\n",
        "\n",
        "yhat_test_average = (yhat_test_1 + yhat_test_2 + yhat_test_3) / 3\n",
        "\n",
        "\n",
        "#各モデルの予測値の平均を取る (訓練データ)\n",
        "yhat_train_1 = multiple_regression.predict(X_train2)\n",
        "yhat_train_2 = polynomial_regression.predict(X_train_poly)\n",
        "yhat_train_3 = xgboost.predict(X_train)\n",
        "\n",
        "yhat_train_average = (yhat_train_1 + yhat_train_2 + yhat_train_3) / 3\n",
        "\n",
        "\n",
        "#精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,Yhat):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, Yhat)\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,Yhat_train,Yhat_test):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,Yhat_train)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,Yhat_test)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / Yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, Yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, Yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, Yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, Yhat_test)) / mean_absolute_error(Y_test, Yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,yhat_train_average,yhat_test_average)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.8711757920413037',\n",
              " 'adjusted_r2(test)      :0.8416104950901084',\n",
              " '平均誤差率(test)       :0.11883711395462686',\n",
              " 'MAE(test)              :2.440346734833879',\n",
              " 'MedianAE(test)         :1.8652607788181186',\n",
              " 'RMSE(test)             :3.6490772407405068',\n",
              " 'RMSE(test) / MAE(test) :1.4953109689918345')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3JWWzIEFAsF"
      },
      "source": [
        "#**サポートベクトルマシン(SVR)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xd8rKGBK7Cz",
        "outputId": "5c392e85-cd1a-4528-efa0-6bc83966b548"
      },
      "source": [
        "# 訓練データとテストデータに分割する。\n",
        "# 本当は町ごとにサンプリングした方がいいと思うが、TODOにしておく。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "# 変数の組み合わせを決定\n",
        "X_train = train[[\"RM\",\"LSTAT\",\"PTRATIO\",\"B\"]]\n",
        "Y_train = train[\"CMEDV\"]\n",
        "X_test = test[[\"RM\",\"LSTAT\",\"PTRATIO\",\"B\"]]\n",
        "Y_test = test[\"CMEDV\"]\n",
        "\n",
        "#SVRのモデル作成\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "model = SVR(kernel='rbf', C=1e3, gamma='scale')\n",
        "#model = SVR(kernel='poly', C=1e3, gamma='scale')\n",
        "#model = SVR(kernel='linear', C=10,gamma='scale')\n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "#精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.6328496989408672',\n",
              " 'adjusted_r2(test)      :0.6318780385281548',\n",
              " '平均誤差率(test)       :0.1739854525137659',\n",
              " 'MAE(test)              :3.760413265830708',\n",
              " 'MedianAE(test)         :2.355126673770974',\n",
              " 'RMSE(test)             :5.840637471080926',\n",
              " 'RMSE(test) / MAE(test) :1.5531903166474652')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qPbLgZMLkJ3"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 18,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVwmbsNqMb-4"
      },
      "source": [
        "#**Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuQDAREJL7oj",
        "outputId": "27b44436-2506-4307-e3b8-d67851fd5e6b"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"http://lib.stat.cmu.edu/datasets/boston_corrected.txt\",skiprows=9,sep=\"\\t\")\n",
        "list(df.columns)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['OBS.',\n",
              " 'TOWN',\n",
              " 'TOWN#',\n",
              " 'TRACT',\n",
              " 'LON',\n",
              " 'LAT',\n",
              " 'MEDV',\n",
              " 'CMEDV',\n",
              " 'CRIM',\n",
              " 'ZN',\n",
              " 'INDUS',\n",
              " 'CHAS',\n",
              " 'NOX',\n",
              " 'RM',\n",
              " 'AGE',\n",
              " 'DIS',\n",
              " 'RAD',\n",
              " 'TAX',\n",
              " 'PTRATIO',\n",
              " 'B',\n",
              " 'LSTAT']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "0WiQH7DisIFh",
        "outputId": "c027db3e-5918-456c-b0d9-0808ab674bec"
      },
      "source": [
        "df"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OBS.</th>\n",
              "      <th>TOWN</th>\n",
              "      <th>TOWN#</th>\n",
              "      <th>TRACT</th>\n",
              "      <th>LON</th>\n",
              "      <th>LAT</th>\n",
              "      <th>MEDV</th>\n",
              "      <th>CMEDV</th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Nahant</td>\n",
              "      <td>0</td>\n",
              "      <td>2011</td>\n",
              "      <td>-70.9550</td>\n",
              "      <td>42.2550</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Swampscott</td>\n",
              "      <td>1</td>\n",
              "      <td>2021</td>\n",
              "      <td>-70.9500</td>\n",
              "      <td>42.2875</td>\n",
              "      <td>21.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Swampscott</td>\n",
              "      <td>1</td>\n",
              "      <td>2022</td>\n",
              "      <td>-70.9360</td>\n",
              "      <td>42.2830</td>\n",
              "      <td>34.7</td>\n",
              "      <td>34.7</td>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Marblehead</td>\n",
              "      <td>2</td>\n",
              "      <td>2031</td>\n",
              "      <td>-70.9280</td>\n",
              "      <td>42.2930</td>\n",
              "      <td>33.4</td>\n",
              "      <td>33.4</td>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Marblehead</td>\n",
              "      <td>2</td>\n",
              "      <td>2032</td>\n",
              "      <td>-70.9220</td>\n",
              "      <td>42.2980</td>\n",
              "      <td>36.2</td>\n",
              "      <td>36.2</td>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>502</td>\n",
              "      <td>Winthrop</td>\n",
              "      <td>91</td>\n",
              "      <td>1801</td>\n",
              "      <td>-70.9860</td>\n",
              "      <td>42.2312</td>\n",
              "      <td>22.4</td>\n",
              "      <td>22.4</td>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>69.1</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>391.99</td>\n",
              "      <td>9.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>503</td>\n",
              "      <td>Winthrop</td>\n",
              "      <td>91</td>\n",
              "      <td>1802</td>\n",
              "      <td>-70.9910</td>\n",
              "      <td>42.2275</td>\n",
              "      <td>20.6</td>\n",
              "      <td>20.6</td>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>76.7</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>504</td>\n",
              "      <td>Winthrop</td>\n",
              "      <td>91</td>\n",
              "      <td>1803</td>\n",
              "      <td>-70.9948</td>\n",
              "      <td>42.2260</td>\n",
              "      <td>23.9</td>\n",
              "      <td>23.9</td>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>505</td>\n",
              "      <td>Winthrop</td>\n",
              "      <td>91</td>\n",
              "      <td>1804</td>\n",
              "      <td>-70.9875</td>\n",
              "      <td>42.2240</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>89.3</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>393.45</td>\n",
              "      <td>6.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>506</td>\n",
              "      <td>Winthrop</td>\n",
              "      <td>91</td>\n",
              "      <td>1805</td>\n",
              "      <td>-70.9825</td>\n",
              "      <td>42.2210</td>\n",
              "      <td>11.9</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>80.8</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>7.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     OBS.        TOWN  TOWN#  TRACT      LON  ...  RAD  TAX  PTRATIO       B  LSTAT\n",
              "0       1      Nahant      0   2011 -70.9550  ...    1  296     15.3  396.90   4.98\n",
              "1       2  Swampscott      1   2021 -70.9500  ...    2  242     17.8  396.90   9.14\n",
              "2       3  Swampscott      1   2022 -70.9360  ...    2  242     17.8  392.83   4.03\n",
              "3       4  Marblehead      2   2031 -70.9280  ...    3  222     18.7  394.63   2.94\n",
              "4       5  Marblehead      2   2032 -70.9220  ...    3  222     18.7  396.90   5.33\n",
              "..    ...         ...    ...    ...      ...  ...  ...  ...      ...     ...    ...\n",
              "501   502    Winthrop     91   1801 -70.9860  ...    1  273     21.0  391.99   9.67\n",
              "502   503    Winthrop     91   1802 -70.9910  ...    1  273     21.0  396.90   9.08\n",
              "503   504    Winthrop     91   1803 -70.9948  ...    1  273     21.0  396.90   5.64\n",
              "504   505    Winthrop     91   1804 -70.9875  ...    1  273     21.0  393.45   6.48\n",
              "505   506    Winthrop     91   1805 -70.9825  ...    1  273     21.0  396.90   7.88\n",
              "\n",
              "[506 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwwcmwczMwfE",
        "outputId": "0c27f2de-ec27-4c5f-c3c8-b99ddc48354e"
      },
      "source": [
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "# 変数の組み合わせは前回の重回帰分析と同じ\n",
        "#X_train = train[[\"RM\",\"LSTAT\",\"PTRATIO\",\"B\"]]\n",
        "#Y_train = train[\"CMEDV\"]\n",
        "#X_test = test[[\"RM\",\"LSTAT\",\"PTRATIO\",\"B\"]]\n",
        "#Y_test = test[\"CMEDV\"]\n",
        "\n",
        "X_train = train[[\"TOWN#\", \"LON\", \"LAT\", \"CRIM\", \"INDUS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"LSTAT\",\"PTRATIO\",\"B\"]]\n",
        "Y_train = train[\"CMEDV\"]\n",
        "X_test = test[[\"TOWN#\", \"LON\", \"LAT\", \"CRIM\", \"INDUS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"LSTAT\",\"PTRATIO\",\"B\"]]\n",
        "Y_test = test[\"CMEDV\"]\n",
        "\n",
        "\n",
        "#正規化する\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)  \n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#モデル作成\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "model = MLPRegressor(hidden_layer_sizes=(100, 100, 50, 50, 50, 50, 50, 50), learning_rate='adaptive', max_iter=500, random_state=42, solver=\"lbfgs\", early_stopping=True) \n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "初期設定：\n",
        "\n",
        "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
        "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
        "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
        "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
        "       verbose=False, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9999188604266616',\n",
              " 'adjusted_r2(test)      :0.883360056611203',\n",
              " '平均誤差率(test)       :0.1277582934332472',\n",
              " 'MAE(test)              :2.327733421204823',\n",
              " 'MedianAE(test)         :1.866043183140718',\n",
              " 'RMSE(test)             :3.1135926682857193',\n",
              " 'RMSE(test) / MAE(test) :1.3376070644181153')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wY8OqRsR79F"
      },
      "source": [
        "#**重回帰分析**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAta-W1TSFuG"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"http://lib.stat.cmu.edu/datasets/boston_corrected.txt\",skiprows=9,sep=\"\\t\")\n",
        "pd.DataFrame(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uLklKm7SLmV"
      },
      "source": [
        "#頭の3行を表示\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iCgoI-XSOle",
        "outputId": "76c28658-1883-406d-b26a-f4d329d5e43e"
      },
      "source": [
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "# 訓練データの件数確認\n",
        "print(\"train: \"+str(train.count()[\"OBS.\"]))\n",
        "\n",
        "# テストデータの件数確認\n",
        "print(\"test: \"+str(test.count()[\"OBS.\"]))\n",
        "\n",
        "\n",
        "# 分析に利用する変数に限定\n",
        "# 本当だったら事前に変数選択で利用するカラムを限定しておく\n",
        "\n",
        "anacols=[\n",
        "  \"CRIM\"  # 1人当たりの犯罪数\n",
        ", \"ZN\" #町別の25,000平方フィート(7600m2)以上の住居区画の割合\n",
        ", \"INDUS\" #町別の非小売業が占める土地面積の割合\n",
        ", \"CHAS\" #チャールズ川沿いかどうか\n",
        ", \"NOX\" #町別の窒素酸化物の濃度\n",
        ", \"RM\" #住居の平均部屋数\n",
        ", \"AGE\" #持ち家住宅\n",
        ", \"DIS\" #5つのボストン雇用センターへの重み付き距離\n",
        ", \"RAD\" #町別の環状高速道路へのアクセスのしやすさ\n",
        ", \"TAX\" #町別の$10,000ドルあたりの固定資産税率\n",
        ", \"PTRATIO\" #町別の生徒と先生の比率\n",
        ", \"B\" #1000*(黒人人口割合 - 0.63)2\n",
        ", \"LSTAT\" #貧困人口割合\n",
        "]\n",
        "\n",
        "# 訓練データ\n",
        "X_train = train[anacols]  # 説明変数\n",
        "Y_train=train[\"CMEDV\"] # 目的変数\n",
        "\n",
        "# テストデータ\n",
        "X_test = test[anacols] # 説明変数\n",
        "Y_test=test[\"CMEDV\"] # 目的変数\n",
        "\n",
        "# 欠損処理\n",
        "# nullがあれば0埋めする。平均値や最頻値でもいい\n",
        "X_train = X_train.fillna(0)\n",
        "Y_train = Y_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "Y_test = Y_test.fillna(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 404\n",
            "test: 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuAHAPlHWSIH"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGmxlJztWprU"
      },
      "source": [
        "Y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZstfNGAWqNI"
      },
      "source": [
        "#精度が一番良いモデルの探索\n",
        "\n",
        "import sys\n",
        "import itertools\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "comblist=[]\n",
        "best_model=None\n",
        "best_features=None\n",
        "best_mae=sys.maxsize\n",
        "\n",
        "# 変数の選択数 (1 ~ 最大選択可能数)\n",
        "for i in range(1,len(anacols) + 1):\n",
        "\n",
        "  # 変数の選択数に合わせた組み合わせを作成\n",
        "  comblist = list(itertools.combinations(anacols,i))\n",
        "  for featurecomb in comblist:\n",
        "    # 重回帰モデル作成\n",
        "    multi_regression = LinearRegression()\n",
        "    multi_regression.fit(X_train[list(featurecomb)],Y_train)\n",
        "\n",
        "    # テストデータに当てはめる\n",
        "    yhat_test = multi_regression.predict(X_test[list(featurecomb)])\n",
        "\n",
        "    # 精度(MAE) 他にも様々な評価方法がある\n",
        "    mae = mean_absolute_error(Y_test, yhat_test)\n",
        "    \n",
        "    #一番よい精度のモデルを探索\n",
        "    if  mae < best_mae:\n",
        "      best_mae = mae\n",
        "      best_features = featurecomb\n",
        "      best_model = multi_regression\n",
        "\n",
        "print(str(best_mae))\n",
        "print(best_features)\n",
        "\n",
        "# 係数逆転現象の確認\n",
        "pd.DataFrame({\"name\":X_train[list(best_features)].columns,\"coefficients\":best_model.coef_})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XnqHjzZXRB-",
        "outputId": "76b5ad1b-dd6a-4632-8771-2107fa7fa758"
      },
      "source": [
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "   from sklearn.metrics import r2_score\n",
        "   import numpy as np\n",
        "   r_squared = r2_score(Y, model.predict(X))\n",
        "   adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "   return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "   from sklearn.metrics import explained_variance_score\n",
        "   from sklearn.metrics import mean_absolute_error\n",
        "   from sklearn.metrics import mean_squared_error\n",
        "   from sklearn.metrics import mean_squared_log_error\n",
        "   from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "   yhat_test = model.predict(X_test)\n",
        "   return  \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train[list(best_features)],Y_train,X_test[list(best_features)],Y_test,best_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.7224056607466813',\n",
              " 'adjusted_r2(test)      :0.7386023143239528',\n",
              " '平均誤差率(test)       :0.15322170833625723',\n",
              " 'MAE(test)              :3.1841915998253896',\n",
              " 'MedianAE(test)         :2.501378017150664',\n",
              " 'RMSE(test)             :4.7670541453730815',\n",
              " 'RMSE(test) / MAE(test) :1.4971002830465638')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    }
  ]
}