{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled47.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/AdvancedPytorch_Colab/blob/master/Attention_branch_network_Github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAahyg9NIph3",
        "colab_type": "text"
      },
      "source": [
        "#Attention branch networkをcolabで実装\n",
        "https://github.com/machine-perception-robotics-group/attention_branch_network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FK0-DdivLFm",
        "colab_type": "code",
        "outputId": "dae7aa47-c35d-48f8-c5fd-05afcda9d8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#dataset.zipを解凍\n",
        "!date -R\n",
        "!unzip -qq drive/My\\ Drive/Deep_learning/attention_branch_network.zip\n",
        "!date -R\n",
        "!ls\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Mon, 13 Apr 2020 08:49:14 +0000\n",
            "Mon, 13 Apr 2020 08:49:22 +0000\n",
            "attention_branch_network-master  drive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpTizePnxmit",
        "colab_type": "code",
        "outputId": "9b2a88e4-a4e4-4492-df67-226664eb60ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/attention_branch_network-master')\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints  example.jpeg  LICENSE  README_en.md  TRAINING.md\n",
            "cifar.py     imagenet.py   models   README.md\t  utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL1jZH6AI9QL",
        "colab_type": "code",
        "outputId": "c4438ea3-e00a-46be-cef5-0ba7a5d98f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "#HELPを参照\n",
        "!python3 imagenet.py -h"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: imagenet.py [-h] [-d DATA] [-j N] [--epochs N] [--start-epoch N]\n",
            "                   [--train-batch N] [--test-batch N] [--lr LR]\n",
            "                   [--drop Dropout] [--schedule SCHEDULE [SCHEDULE ...]]\n",
            "                   [--gamma GAMMA] [--momentum M] [--weight-decay W] [-c PATH]\n",
            "                   [--resume PATH] [--arch ARCH] [--depth DEPTH]\n",
            "                   [--cardinality CARDINALITY] [--base-width BASE_WIDTH]\n",
            "                   [--widen-factor WIDEN_FACTOR] [--manualSeed MANUALSEED]\n",
            "                   [-e] [--pretrained] [--gpu-id GPU_ID]\n",
            "\n",
            "PyTorch ImageNet Training\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -d DATA, --data DATA\n",
            "  -j N, --workers N     number of data loading workers (default: 4)\n",
            "  --epochs N            number of total epochs to run\n",
            "  --start-epoch N       manual epoch number (useful on restarts)\n",
            "  --train-batch N       train batchsize (default: 256)\n",
            "  --test-batch N        test batchsize (default: 200)\n",
            "  --lr LR, --learning-rate LR\n",
            "                        initial learning rate\n",
            "  --drop Dropout, --dropout Dropout\n",
            "                        Dropout ratio\n",
            "  --schedule SCHEDULE [SCHEDULE ...]\n",
            "                        Decrease learning rate at these epochs.\n",
            "  --gamma GAMMA         LR is multiplied by gamma on schedule.\n",
            "  --momentum M          momentum\n",
            "  --weight-decay W, --wd W\n",
            "                        weight decay (default: 1e-4)\n",
            "  -c PATH, --checkpoint PATH\n",
            "                        path to save checkpoint (default: checkpoint)\n",
            "  --resume PATH         path to latest checkpoint (default: none)\n",
            "  --arch ARCH, -a ARCH  model architecture: resnet101 | resnet152 | resnet18 |\n",
            "                        resnet34 | resnet50 | se_resnet_101 | se_resnet_152 |\n",
            "                        se_resnet_18 | se_resnet_34 | se_resnet_50 (default:\n",
            "                        resnet18)\n",
            "  --depth DEPTH         Model depth.\n",
            "  --cardinality CARDINALITY\n",
            "                        ResNet cardinality (group).\n",
            "  --base-width BASE_WIDTH\n",
            "                        ResNet base width.\n",
            "  --widen-factor WIDEN_FACTOR\n",
            "                        Widen factor. 4 -> 64, 8 -> 128, ...\n",
            "  --manualSeed MANUALSEED\n",
            "                        manual seed\n",
            "  -e, --evaluate        evaluate model on validation set\n",
            "  --pretrained          use pre-trained model\n",
            "  --gpu-id GPU_ID       id(s) for CUDA_VISIBLE_DEVICES\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm-j3mlhx57G",
        "colab_type": "code",
        "outputId": "9ede9682-b4e0-468e-9be6-f937dcd85cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "!python3 imagenet.py -d \"/content/drive/My Drive/Deep_learning/applstra/\" -a resnet18 -e"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:704: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
            "  \"please use transforms.RandomResizedCrop instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "=> creating model 'resnet18'\n",
            "    Total params: 21.61M\n",
            "\n",
            "Evaluation only\n",
            "Traceback (most recent call last):\n",
            "  File \"imagenet.py\", line 399, in <module>\n",
            "    main()\n",
            "  File \"imagenet.py\", line 193, in main\n",
            "    test_loss, test_acc = test(val_loader, model, criterion, start_epoch, use_cuda)\n",
            "  File \"imagenet.py\", line 296, in test\n",
            "    fc = open('categorie.txt', 'r')\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'categorie.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6nrbbd0w5Ro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cb9669d-3e23-4ab3-bc10-6e09c96034cd"
      },
      "source": [
        "os.path.join(\"/content/drive/My Drive/Deep_learning/applstra/\", 'train')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Deep_learning/applstra/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}